## Thoughts of ffmpeg and whisper filters

_January 2026_

I've been experimenting with `ffmpeg` and the `whisper` filters. In general I think its awesome that such functionality exists, but at the same time, I don't believe it addresses the particular painpoints when you go beyond the 'obvious' thing. 

### Installation

On `macos` to install `ffmpeg` with the `whisper` filters, the easiest way is via [brew](https://github.com/homebrew-ffmpeg/homebrew-ffmpeg/): 

```
brew tap homebrew-ffmpeg/ffmpeg
brew install homebrew-ffmpeg/ffmpeg/ffmpeg --with-whisper-cpp
```

### Considerations

One of the cool functionalities of `whisper-cpp` is the ability to integrate voice activity detection (VAD). This works out of the box with the whisper filter. Unfortunately what does not work is integrating translations, instead it is expected you create the translation yourself.

Anecdotally, the performance of the setup is lacking. In fact it is slower than:

- extracting the raw audio out of the base media file
- using whisper-cpp to generate the srt

In code it will look something like:

```sh
ffmpeg -i '{{input_path}}' -vn -acodec libvorbis -q:a 0 '{{output_path}}'
whisper-cli -m path/to/ggml-large-v3-turbo-q5_0.bin -sns -osrt --vad -vm path/to/ggml-silero-v6.2.0.bin -of '{{output_path}}' -f '{{input_path}}' -l en
```

As of right now, I'll probably stick with running it manually in this way. 

### Further Notes

If you need translations don't use `large-v3-turbo` you'll need a non-turbo model otherwise translations won't work. 

Sometimes when using VAD it screws up the `srt` timings, I have a hacky fix which:

- calculates the median time
- finds timings which are more than double the median time
- tries to fix it

It also tries to fix timestamps which are very short, and can be extended (due to there not being a subtitle in the frame before).
Using median also means the outputs will be idempotent.

```py
import srt
import numpy as np
from pathlib import Path


def fix_srt_timestamp(input_srt_path: str | Path):
    """
    Sometimes whispers generates really long timestamps.
    This calculates the median duration, clipping timestamps that are double the length
    and replacing with the median duration.
    """
    data = Path(input_srt_path).read_text()
    if data.strip() == "":
        Path(input_srt_path).unlink()
    subs = list(srt.parse(data))
    if len(subs) < 2:
        return
    # median
    median_time = np.median([sub.end - sub.start for sub in subs])
    fixed_subs = []
    counter = 0
    for sub in subs:
        duration = sub.end - sub.start
        if duration > median_time * 2:
            sub.start = sub.end - median_time
            counter += 1

        # other fixes
        sub.content = sub.content.strip()

        # remove if single word
        if len(sub.content.split()) <= 1:
            counter += 1
            continue

        # if the time between current and previous one is < median but > median/2 make it median/2
        if len(fixed_subs) > 0:
            sub_time_diff = sub.start - fixed_subs[-1].end
            if median_time / 2 < sub_time_diff < median_time:
                prev_sub = fixed_subs[-1]
                prev_sub.end = prev_sub.end + sub_time_diff / 2
                sub.start = sub.start - sub_time_diff / 2
                fixed_subs[-1] = prev_sub
                counter += 1

            elif (
                sub.start - fixed_subs[-1].end > median_time
                and sub.end - sub.start < median_time
            ):
                sub.start = sub.end - median_time
                counter += 1
        fixed_subs.append(sub)

    fixed_srt = srt.compose(fixed_subs)
    Path(input_srt_path).write_text(fixed_srt)
    if counter > 0:
        print(f"Fixed {counter} timestamps in {input_srt_path}")
```