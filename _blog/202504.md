## Maintaining Scripts using Just and Gum

_April 2025_

I've found maintaining shell scripts and aliases to be a bit of a mess. I know people have their own systems with dotfiles, but it never 'stuck' with me. I'm trialing a new approach using [gum](https://github.com/charmbracelet/gum/) and [just](https://github.com/casey/just), both which can be installed via `brew`. This makes it so there less memorisation of what different programs do, and their parameters, since you can control and name variables to a flow that you like. Combined with `just`'s ability to target `justfile` from different directories, this makes centralising scripts and cli commands very straightforward. 

For example, the following are roughly equivalent:

```
$ just foo/a b
$ (cd foo && just a b)
```

To avoid the `cd`, the annotation `[no-cd]` can be used. Putting this altogether, I can for example have some "global" scripts that converts video to audio, or downloads youtube videos using the following recipe:

```makefile
[no-cd]
convert_to_audio:
    FILE=$(gum file)
    ffmpeg -i $FILE -vn -acodec libvorbis -q:a 0 $FILE.ogg

[no-cd]
download_video:
    uvx yt-dlp@latest -S "res:$(gum choose 1080 720 480 360 240 144)" $(gum input)
```

Edit: _August 2025_

Recently when trying to setup API keys and authentication for a locally running service, I ended up using `gum` to tackle having a 'lightweight' approach to avoid having credentials in files. In a nutshell it would look something like:

```makefile
run_server:
    API_KEY=$(gum input --password)
    start-server.sh
```

## Syncify Python Async Functions

_April 2025_

There's a lot to unpack with Python shenanigans. Including why [nest-asyncio](https://pypi.org/project/nest-asyncio/) even exists. Here is yet another pattern (note: you really should look into https://asyncer.tiangolo.com/ if it fits for you). 

```py
def syncify(func, *args, **kwargs):
    def wrapper(coro):
        return asyncio.run(coro)

    with ThreadPoolExecutor(max_workers=1) as executor:
        result = next(executor.map(wrapper, [func(*args, **kwargs)]))
    return result
```

Which delegates/moves the execution to a threadpool to bypass potential issues. This is definitely not a 'performant' option, but it may save your skin. 

I'll point out in general, where your event loop is not nested, you could just use `asyncio.run`.

## Python MCP - Mounting to an Existing FastAPI ASGI Server

_April 2025_

You can mount the SSE server to an existing FastAPI ASGI server dynamically. The way I've made it work is as follows:


```py
sse = SseServerTransport(...)

...
app.router.routes.append(Mount("/messages", app=sse.handle_post_message))

@app.get("/sse")
async def handle_mcp_connection(request: Request):
    async with sse.connect(sse(request.scope, request.receive, request.send) as (
        read_stream,
        write_stream,
    ):
        await mcp._mcp_server.run(
            read_stream,
            write_stream,
            mcp._mcp_server.create_initialization_options(),
        )
```

This seemed to work pretty well, along with having Redis as an intermediary broker for dealing with state.

